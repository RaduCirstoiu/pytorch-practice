{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient reversal pytorch\n",
    "\n",
    "Inspired from the following tweets:\n",
    "\n",
    "* https://twitter.com/mat_kelcey/status/932149793765261313\n",
    "* https://twitter.com/ericjang11/status/932073259721359363\n",
    "\n",
    "Basic idea:\n",
    "\n",
    "```python\n",
    "# Add something to gradient\n",
    "f(x) + g(x) - tf.stop_gradients(g(x))\n",
    "\n",
    "# Reverse gradient\n",
    "tf.stop_gradient(f(x)*2) - f(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    return X*X\n",
    "\n",
    "def g(X):\n",
    "    return X**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.55617105,  0.13785352,  0.20610955, -0.8133813 , -1.14285471,\n",
       "        1.13275964,  0.79103318,  0.14766171, -1.03148017,  0.36393108])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_X = tf.Variable(X)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.55617105,  0.13785352,  0.20610955, -0.8133813 , -1.14285471,\n",
       "        1.13275964,  0.79103318,  0.14766171, -1.03148017,  0.36393108])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(init_op)\n",
    "sess.run(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forward_op = f(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.53401042,  0.01900359,  0.04248115,  0.66158914,  1.3061169 ,\n",
       "        1.28314441,  0.62573349,  0.02180398,  1.06395134,  0.13244583])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(forward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_op = tf.gradients(forward_op, tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-5.1123421 ,  0.27570704,  0.4122191 , -1.6267626 , -2.28570943,\n",
       "         2.26551928,  1.58206636,  0.29532342, -2.06296033,  0.72786216])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.1123421 ,  0.27570704,  0.4122191 , -1.6267626 , -2.28570943,\n",
       "        2.26551928,  1.58206636,  0.29532342, -2.06296033,  0.72786216])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*2 # This should match the gradient above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the gradients\n",
    "Keep forward pass the same. \n",
    "The trick is to add $g(x)$, such that $g'(x)$ is the gradient modifier, during the forward pass and substract it as well. But stop gradients from flowing through the substraction part. \n",
    "\n",
    "$f(x) + g(x) - g(x)$ will lead to gradients $f'(x) + g'(x) -g'(x)$. Since gradients don't flow through $-g'(x)$, hence we get new gradients as $f'(x) + g'(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_modifier_op = g(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.67020483e+01,   2.61971220e-03,   8.75577023e-03,\n",
       "        -5.38124238e-01,  -1.49270185e+00,   1.45349420e+00,\n",
       "         4.94975949e-01,   3.21961304e-03,  -1.09744470e+00,\n",
       "         4.82011548e-02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_modifier_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_forward_op = (f(tf_X) + g(tf_X) - tf.stop_gradient(g(tf_X)))\n",
    "modified_backward_op = tf.gradients(modified_forward_op, tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.53401042,  0.01900359,  0.04248115,  0.66158914,  1.3061169 ,\n",
       "        1.28314441,  0.62573349,  0.02180398,  1.06395134,  0.13244583])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(modified_forward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 14.48968918,   0.33271782,   0.53966255,   0.35800482,\n",
       "          1.63264126,   6.1149525 ,   3.45926682,   0.36073536,\n",
       "          1.12889367,   1.12519966])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(modified_backward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.48968918,   0.33271782,   0.53966255,   0.35800482,\n",
       "         1.63264126,   6.1149525 ,   3.45926682,   0.36073536,\n",
       "         1.12889367,   1.12519966])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X + 3*(X**2) # This should match the gradients above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient reversal\n",
    "\n",
    "Here the modifying function $g(x)$ is simply the $-2*f(x)$, this will make the gradients $-f'(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_reversal_op = (tf.stop_gradient(2*f(tf_X)) - f(tf_X))\n",
    "gradient_reversal_grad_op = tf.gradients(gradient_reversal_op, tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.53401042,  0.01900359,  0.04248115,  0.66158914,  1.3061169 ,\n",
       "        1.28314441,  0.62573349,  0.02180398,  1.06395134,  0.13244583])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_reversal_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 5.1123421 , -0.27570704, -0.4122191 ,  1.6267626 ,  2.28570943,\n",
       "        -2.26551928, -1.58206636, -0.29532342,  2.06296033, -0.72786216])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_reversal_grad_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run((gradient_op[0] + gradient_reversal_grad_op[0])) # This should be zero. Signifying grad is reversed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytoch case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_grad(X):\n",
    "    if X.grad is not None:\n",
    "        X.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch_X = Variable(torch.FloatTensor(X), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.55617094,  0.13785352,  0.20610955, -0.81338131, -1.14285469,\n",
       "        1.13275969,  0.79103315,  0.14766172, -1.03148019,  0.36393109], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_X.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.53400993,  0.01900359,  0.04248115,  0.66158915,  1.30611682,\n",
       "        1.28314447,  0.62573344,  0.02180398,  1.06395137,  0.13244584], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch_X).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.67020454e+01,   2.61971215e-03,   8.75577051e-03,\n",
       "        -5.38124263e-01,  -1.49270177e+00,   1.45349431e+00,\n",
       "         4.94975895e-01,   3.21961334e-03,  -1.09744477e+00,\n",
       "         4.82011586e-02], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(torch_X).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.11234188,  0.27570704,  0.41221911, -1.62676263, -2.28570938,\n",
       "        2.26551938,  1.5820663 ,  0.29532343, -2.06296039,  0.72786218], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_grad(torch_X)\n",
    "f_X = f(torch_X)\n",
    "f_X.backward(torch.ones(f_X.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.1123421 ,  0.27570704,  0.4122191 , -1.6267626 , -2.28570943,\n",
       "        2.26551928,  1.58206636,  0.29532342, -2.06296033,  0.72786216])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_gradients_forward = lambda x: f(x) + g(x) - g(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.48968792,   0.33271781,   0.53966254,   0.35800481,\n",
       "         1.63264108,   6.11495304,   3.45926666,   0.36073539,\n",
       "         1.12889361,   1.12519968], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_grad(torch_X)\n",
    "modified_grad = modified_gradients_forward(torch_X)\n",
    "modified_grad.backward(torch.ones(modified_grad.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.48968918,   0.33271782,   0.53966255,   0.35800482,\n",
       "         1.63264126,   6.1149525 ,   3.45926682,   0.36073536,\n",
       "         1.12889367,   1.12519966])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X + 3*(X*X) # It should be same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradien reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_reversal = lambda x: (2*f(x)).detach() - f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.11234188, -0.27570704, -0.41221911,  1.62676263,  2.28570938,\n",
       "       -2.26551938, -1.5820663 , -0.29532343,  2.06296039, -0.72786218], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_grad(torch_X)\n",
    "grad_reverse = gradient_reversal(torch_X)\n",
    "grad_reverse.backward(torch.ones(grad_reverse.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1123421 , -0.27570704, -0.4122191 ,  1.6267626 ,  2.28570943,\n",
       "       -2.26551928, -1.58206636, -0.29532342,  2.06296033, -0.72786216])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2*X # It should be same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
