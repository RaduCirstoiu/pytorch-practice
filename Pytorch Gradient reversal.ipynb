{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient reversal pytorch\n",
    "\n",
    "Inspired from the following tweets:\n",
    "\n",
    "* https://twitter.com/mat_kelcey/status/932149793765261313\n",
    "* https://twitter.com/ericjang11/status/932073259721359363\n",
    "\n",
    "Basic idea:\n",
    "\n",
    "```python\n",
    "# Add something to gradient\n",
    "f(x) + g(x) - tf.stop_gradients(g(x))\n",
    "\n",
    "# Reverse gradient\n",
    "tf.stop_gradient(f(x)*2) - f(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    return X*X\n",
    "\n",
    "def g(X):\n",
    "    return X**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01995021, -0.32892969,  0.75804777,  0.172995  ,  0.69747771,\n",
       "        1.11414039, -0.69194092,  2.43364877,  0.92732815, -0.91409348])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_X = tf.Variable(X)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01995021, -0.32892969,  0.75804777,  0.172995  ,  0.69747771,\n",
       "        1.11414039, -0.69194092,  2.43364877,  0.92732815, -0.91409348])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(init_op)\n",
    "sess.run(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forward_op = f(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.98010770e-04,   1.08194738e-01,   5.74636421e-01,\n",
       "         2.99272683e-02,   4.86475162e-01,   1.24130881e+00,\n",
       "         4.78782241e-01,   5.92264633e+00,   8.59937506e-01,\n",
       "         8.35566890e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(forward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_op = tf.gradients(forward_op, tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03990041, -0.65785937,  1.51609554,  0.34598999,  1.39495543,\n",
       "         2.22828078, -1.38388185,  4.86729754,  1.85465631, -1.82818696])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03990041, -0.65785937,  1.51609554,  0.34598999,  1.39495543,\n",
       "        2.22828078, -1.38388185,  4.86729754,  1.85465631, -1.82818696])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*2 # This should match the gradient above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the gradients\n",
    "Keep forward pass the same. \n",
    "The trick is to add $g(x)$, such that $g'(x)$ is the gradient modifier, during the forward pass and substract it as well. But stop gradients from flowing through the substraction part. \n",
    "\n",
    "$f(x) + g(x) - g(x)$ will lead to gradients $f'(x) + g'(x) -g'(x)$. Since gradients don't flow through $-g'(x)$, hence we get new gradients as $f'(x) + g'(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_modifier_op = g(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.94039737e-06,  -3.55884610e-02,   4.35601858e-01,\n",
       "         5.17726764e-03,   3.39305584e-01,   1.38299228e+00,\n",
       "        -3.31289026e-01,   1.44136410e+01,   7.97444260e-01,\n",
       "        -7.63786246e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_modifier_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_forward_op = (f(tf_X) + g(tf_X) - tf.stop_gradient(g(tf_X)))\n",
    "modified_backward_op = tf.gradients(modified_forward_op, tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.98010770e-04,   1.08194738e-01,   5.74636421e-01,\n",
       "         2.99272683e-02,   4.86475162e-01,   1.24130881e+00,\n",
       "         4.78782241e-01,   5.92264633e+00,   8.59937506e-01,\n",
       "         8.35566890e-01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(modified_forward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.04109445,  -0.33327516,   3.2400048 ,   0.4357718 ,\n",
       "          2.85438092,   5.95220721,   0.05246488,  22.63523654,\n",
       "          4.43446883,   0.67851371])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(modified_backward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.04109445,  -0.33327516,   3.2400048 ,   0.4357718 ,\n",
       "         2.85438092,   5.95220721,   0.05246488,  22.63523654,\n",
       "         4.43446883,   0.67851371])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X + 3*(X**2) # This should match the gradients above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient reversal\n",
    "\n",
    "Here the modifying function $g(x)$ is simply the $-2*f(x)$, this will make the gradients $-f'(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_reversal_op = (tf.stop_gradient(2*f(tf_X)) - f(tf_X))\n",
    "gradient_reversal_grad_op = tf.gradients(gradient_reversal_op, tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.98010770e-04,   1.08194738e-01,   5.74636421e-01,\n",
       "         2.99272683e-02,   4.86475162e-01,   1.24130881e+00,\n",
       "         4.78782241e-01,   5.92264633e+00,   8.59937506e-01,\n",
       "         8.35566890e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_reversal_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.03990041,  0.65785937, -1.51609554, -0.34598999, -1.39495543,\n",
       "        -2.22828078,  1.38388185, -4.86729754, -1.85465631,  1.82818696])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(gradient_reversal_grad_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run((gradient_op[0] + gradient_reversal_grad_op[0])) # This should be zero. Signifying grad is reversed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytoch case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_grad(X):\n",
    "    if X.grad is not None:\n",
    "        X.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch_X = Variable(torch.FloatTensor(X), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01995021, -0.32892969,  0.75804776,  0.172995  ,  0.6974777 ,\n",
       "        1.11414039, -0.6919409 ,  2.43364882,  0.92732817, -0.91409349], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_X.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.98010772e-04,   1.08194746e-01,   5.74636400e-01,\n",
       "         2.99272705e-02,   4.86475140e-01,   1.24130881e+00,\n",
       "         4.78782207e-01,   5.92264652e+00,   8.59937549e-01,\n",
       "         8.35566938e-01], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch_X).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.94039715e-06,  -3.55884619e-02,   4.35601830e-01,\n",
       "         5.17726783e-03,   3.39305550e-01,   1.38299227e+00,\n",
       "        -3.31288993e-01,   1.44136410e+01,   7.97444284e-01,\n",
       "        -7.63786316e-01], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(torch_X).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03990041, -0.65785939,  1.51609552,  0.34599   ,  1.3949554 ,\n",
       "        2.22828078, -1.38388181,  4.86729765,  1.85465634, -1.82818699], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_grad(torch_X)\n",
    "f_X = f(torch_X)\n",
    "f_X.backward(torch.ones(f_X.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03990041, -0.65785937,  1.51609554,  0.34598999,  1.39495543,\n",
       "        2.22828078, -1.38388185,  4.86729754,  1.85465631, -1.82818696])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modified_gradients_forward = lambda x: f(x) + g(x) - g(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.04109445,  -0.33327514,   3.24000454,   0.43577182,\n",
       "         2.85438085,   5.95220757,   0.05246484,  22.63523865,\n",
       "         4.43446875,   0.67851377], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_grad(torch_X)\n",
    "modified_grad = modified_gradients_forward(torch_X)\n",
    "modified_grad.backward(torch.ones(modified_grad.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.04109445,  -0.33327516,   3.2400048 ,   0.4357718 ,\n",
       "         2.85438092,   5.95220721,   0.05246488,  22.63523654,\n",
       "         4.43446883,   0.67851371])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X + 3*(X*X) # It should be same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_reversal = lambda x: (2*f(x)).detach() - f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03990041,  0.65785939, -1.51609552, -0.34599   , -1.3949554 ,\n",
       "       -2.22828078,  1.38388181, -4.86729765, -1.85465634,  1.82818699], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_grad(torch_X)\n",
    "grad_reverse = gradient_reversal(torch_X)\n",
    "grad_reverse.backward(torch.ones(grad_reverse.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03990041,  0.65785937, -1.51609554, -0.34598999, -1.39495543,\n",
       "       -2.22828078,  1.38388185, -4.86729754, -1.85465631,  1.82818696])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2*X # It should be same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch backward hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03990041,  0.65785939, -1.51609552, -0.34599   , -1.3949554 ,\n",
       "       -2.22828078,  1.38388181, -4.86729765, -1.85465634,  1.82818699], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient reversal\n",
    "zero_grad(torch_X)\n",
    "f_X = f(torch_X)\n",
    "f_X.register_hook(lambda grad: -grad)\n",
    "f_X.backward(torch.ones(f_X.size()))\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03990041,  0.65785937, -1.51609554, -0.34598999, -1.39495543,\n",
       "       -2.22828078,  1.38388185, -4.86729754, -1.85465631,  1.82818696])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.04109445,  -0.33327514,   3.24000454,   0.43577182,\n",
       "         2.85438085,   5.95220757,   0.05246484,  22.63523865,\n",
       "         4.43446875,   0.67851377], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified grad example\n",
    "zero_grad(torch_X)\n",
    "h = torch_X.register_hook(lambda grad: grad + 3*(torch_X*torch_X))\n",
    "f_X = f(torch_X)\n",
    "f_X.backward(torch.ones(f_X.size()))\n",
    "h.remove()\n",
    "torch_X.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.04109445,  -0.33327516,   3.2400048 ,   0.4357718 ,\n",
       "         2.85438092,   5.95220721,   0.05246488,  22.63523654,\n",
       "         4.43446883,   0.67851371])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*X + 3*(X*X) # It should be same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
